# -*- coding: utf-8 -*-
"""Deep_Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zUK0o653qmCTS5zLipL2CHdLgeFFPs1E
"""

from google.colab import drive
drive.mount("/content/drive", force_remount=True)

!ls /content/drive/MyDrive

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import h5py as h5py
import PIL

# Others
import numpy as np
from sklearn.model_selection import train_test_split

# For AUC estimation and ROC plots
from sklearn.metrics import roc_curve, auc

# Plots
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

# Image and directories
import cv2
import os



# Tensorflow
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import optimizers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from tensorflow import keras

ImageSize = (224,224)
BatchSize = 64

!wget "https://uwoca-my.sharepoint.com/:u:/g/personal/cbravoro_uwo_ca/Ea8hL1Qqz-1DqXPUkFg3_OkBkT_oOJ5EdvwX1YU_afWF1w?download=1"

!mv Ea8hL1Qqz-1DqXPUkFg3_OkBkT_oOJ5EdvwX1YU_afWF1w?download=1 drive/MyDrive/data.tar.gz
!tar -xf drive/MyDrive/data.tar.gz -C drive/MyDrive

df = pd.read_csv('drive/MyDrive/EmbeddingData_C3_9528.csv')

df.describe()

import os 
df['path'] = df['id'].apply(lambda x: os.path.join('drive/MyDrive/new/LIDAR/', 'LIDAR_' + str(x) + '.png')).tolist()

import os
x = []
for ii, i in enumerate(df['path']):
  if os.path.isfile(i) is False:
    x.append(i)
len(x)

from scipy.stats import zscore
# df['health'] = zscore(df['health'])
df['health'] = df['health'] - df['health'].min()

plt.hist(df['health'])
plt.show()

from sklearn.model_selection import train_test_split
train, test = train_test_split(df, test_size=0.2, random_state=250542531)

from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input
model = VGG19(weights = 'imagenet',      # The weights from the ImageNet competition
              include_top = False,       # Do not include the top layer, which classifies.
              input_shape= (224, 224, 3) # Input shape. Three channels, and BGR (NOT RGB!!!)
             )

from tensorflow.keras.utils import plot_model
from IPython.display import Image

plot_model(model, show_shapes=True, show_layer_names=True, to_file='drive/MyDrive/GraphModel.png')
Image(retina=True, filename='drive/MyDrive/GraphModel.png')

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import optimizers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *

# Create new model
CBModel = Sequential()

# Copy the layers to our new model. This needs to be done as there is a bug in Keras.

for layer in model.layers:
  CBModel.add(layer)

# Set the layers as untrainable
for layer in CBModel.layers:
    layer.trainable = False

CBModel.summary()

# Set layer as trainable.
CBModel.layers[-2].trainable = True
CBModel.layers[-3].trainable = True

# We now add the new layers for prediction.
CBModel.add(Flatten(input_shape=model.output_shape[1:]))
CBModel.add(Dense(64, activation = 'relu'))
CBModel.add(Dropout(0.5))
CBModel.add(Dense(64, activation = 'relu'))
CBModel.add(Dropout(0.5))
CBModel.add(Dense(1, activation = 'relu'))

CBModel.summary()

# Compiling the model!
import tensorflow.keras as keras
CBModel.compile(loss='MeanSquaredError', 
              optimizer=optimizers.SGD(learning_rate=0.00001),
              metrics=[keras.metrics.MeanSquaredError()]
              )

!nvidia-smi -L

# prepare data augmentation configuration. One for train, one for test.
train_datagen = ImageDataGenerator(
                                  rescale=1/255,                         # NNets like small inputs. Rescale.
                                  shear_range=0.2,                          # Shear?
                                  zoom_range=0.2,                           # Zoom? 0.2 means from 80% to 120%
                                  horizontal_flip=True,                     # Flip horizontally?
                                  vertical_flip=True,                      # Flip vertically?
                                  preprocessing_function=preprocess_input,  # VGG expects specific input. Set it up with this function that comes prepackaged.
                                  validation_split = 0.2                    # Create a validation cut?
                                  )

test_datagen = ImageDataGenerator(
                                  rescale=1/255,                       # NNets like small inputs. Rescale.
                                  shear_range=0,                          # Shear?
                                  zoom_range=0,                           # Zoom? 0.2 means from 80% to 120%
                                  horizontal_flip=False,                  # Flip horizontally?
                                  vertical_flip=False,                    # Flip vertically?
                                  preprocessing_function=preprocess_input,# VGG expects specific input. Set it up with this function that comes prepackaged.
                                  validation_split = 0                    # No validation cut for test.
                                  )


# We will use a batch size of 64. Depends on RAM of GPU.
batch_size = 64


# VGG requires 224 x 224 images.
(img_height, img_width) = (224, 224)

train_generator = train_datagen.flow_from_dataframe(train,                      # Where are the pics
                                                    target_size=(img_height, img_width), # What size should they be
                                                    batch_size=batch_size,               # Size of batch
                                                    class_mode='raw',            # Class mode, whether 'binary' or 'categorical'
                                                    subset = 'training',                 # What subset to use?
                                                    shuffle = True,                       # Shuffle the data?
                                                    x_col='path', 
                                                    y_col='health'
                                                    )

validation_generator = train_datagen.flow_from_dataframe(train,                      # Where are the pics
                                                    target_size=(img_height, img_width), # What size should they be
                                                    batch_size=batch_size,               # Size of batch
                                                    class_mode='raw',            # Class mode, whether 'binary' or 'categorical'
                                                    subset = 'validation',               # What subset to use?
                                                    shuffle = True,                       # Shuffle the data?
                                                    x_col='path', 
                                                    y_col='health'
                                                    )

test_generator = test_datagen.flow_from_dataframe(test,
                                                  target_size=(img_height, img_width),
                                                  batch_size=1, # Pass images one-by-one
                                                  class_mode='raw',
                                                  shuffle = False, # Test set does NOT shuffle the data.
                                                  x_col='path',
                                                  y_col='health'
                                                  )

steps_per_epoch = 0.8 * len(train)/batch_size
validation_steps = 0.2 * len(train)/batch_size
print(steps_per_epoch)
print(validation_steps)

if not os.path.isdir('drive/MyDrive/checkpoints/'):
  os.mkdir('drive/MyDrive/checkpoints/')

# Define callbacks
checkpoint_path='drive/MyDrive/checkpoints/VGG19.{epoch:02d}-{val_loss:.2f}.h5'
checkpoint_dir=os.path.dirname(checkpoint_path)

my_callbacks = [
    # Stop training if validation error stays within 0.00001 for three rounds.
    tf.keras.callbacks.EarlyStopping(monitor='val_loss',
                                     min_delta=0.00001,
                                     patience=3),
    # Save the weights of the best performing model to the checkpoint folder.
    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                       save_best_only=True,
                                       save_weights_only=True),
]

# Number of epochs
epochs = 10

# Train!
CBModel.fit(train_generator,
            epochs=epochs,
            validation_data=validation_generator,
            steps_per_epoch = 367, # Usually cases / batch_size = 183. Reduced to 32 so it runs faster.
            validation_steps = 91, # Number of validation steps . Again cases / batch_size = 45.
            callbacks=my_callbacks
          )

loss = CBModel.history.history['loss']
val_loss = CBModel.history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# CBModel.save('drive/MyDrive/VGG_lr0.00001.h5')
# Loading
# CBModel = keras.models.load_model('drive/MyDrive/VGG_lr0.00001.h5')

CBModel.load_weights('drive/MyDrive/checkpoints/VGG19.04-0.66.h5')

# Applying to the test set with a generator.
test_generator.reset()

# Get probabilities
output = CBModel.predict(test_generator)

output

test['VGG'] = output
test.to_csv('drive/MyDrive/checkpoints/test_vgg.csv')

def mean_absolute_percentage_error(y_true, y_pred): 
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100


mape = mean_absolute_percentage_error(test_generator.labels, output) + 1
print('The mean absolute percentual error over the test is %.2f%%' % mape)

plt.plot(test['health'], test['VGG'], '.')
plt.xlabel('Health')
plt.ylabel('VGG')
plt.show()

import tensorflow as tf
A= pd.read_csv('drive/MyDrive/checkpoints/test_vgg.csv')
A.columns
mse = tf.keras.metrics.RootMeanSquaredError()
mse(A['health'], A['VGG']).numpy()

# Print the predictions
preds = CBModel.predict(data/255)
print(preds)

"""**ResNET Implementation**"""

# Import base model. Using ResNet50v2.
from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input

# Import model with input layer
base_model = ResNet50V2(weights = 'imagenet',     # The weights from the ImageNet competition
                      include_top = False,       # Do not include the top layer, which classifies.
                      input_shape= (224, 224, 3) # Input shape. Three channels.
                      )

# Set the base model to untrainable.
base_model.trainable = False

# Create the full model using the Model API

# Input layer
inputs = keras.Input(shape=ImageSize + (3,),
                        name = 'image_only_input')

# Add the ResNet model, setting it to be untrainable. 
# First we store it on a temporary variable.
x = base_model(inputs, training=False)

# Flatten to make it the same size as the original model
x = Flatten()(x)

# Now we actually add it to a layer. Note the way of writing it.
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)

# Add final output layer.
outputs = Dense(1, activation='LeakyReLU')(x)

# Create the complete model object
ResnetModel = keras.Model(inputs, outputs)

# This is what the model looks like now.
ResnetModel.summary()

# Compiling the model! Note the learning rate.
opt = optimizers.Adam(learning_rate=1e-6,            # Learning rate needs to be tweaked for convergence and be small!
                      decay=1e-3 / 500    # Decay of the LR 10^-3 / 1 / 50 / 100 / 200
                      ) 
ResnetModel.compile(loss=keras.losses.MeanSquaredError(), # This is NOT a classification problem!
                      optimizer=opt
                       )

# Define parameters

target_size = (224, 224)
batch_size = 32

# Define generators
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.resnet_v2 import preprocess_input

train_datagen = ImageDataGenerator(rescale=None,                         # Inputs are scaled in the preprocessing function
                                  shear_range=0.2,                          # Shear?
                                  zoom_range=0.2,                           # Zoom? 0.2 means from 80% to 120%
                                  horizontal_flip=True,                     # Flip horizontally?
                                  vertical_flip=True,                      # Flip vertically?
                                  preprocessing_function=preprocess_input,  # ResNet expects specific input. Set it up with this function that comes prepackaged.
                                  validation_split = 0.2                    # Create a validation cut?
                                  )

test_datagen = ImageDataGenerator(rescale=None,                        # Inputs are scaled in the preprocessing function
                                  shear_range=0,                          # Shear?
                                  zoom_range=0,                           # Zoom? 0.2 means from 80% to 120%
                                  horizontal_flip=True,                     # Flip horizontally?
                                  vertical_flip=True,                      # Flip vertically?
                                  preprocessing_function=preprocess_input,  # VGG expects specific input. Set it up with this function that comes prepackaged.
                                  )

# Point to the data and **give the targets**. Note the "raw" class_mode
train_generator = train_datagen.flow_from_dataframe(train,
                                                    x_col='path',   # Path to images
                                                    y_col='health',  # Target
                                                    target_size=target_size, # Same as last lab
                                                    batch_size=batch_size,
                                                    shuffle=True,
                                                    class_mode='raw',
                                                    subset='training',
                                                    interpolation="bilinear"
                                                   )

validation_generator = train_datagen.flow_from_dataframe(train,
                                                    x_col='path',
                                                    y_col='health',
                                                    target_size=target_size,
                                                    batch_size=batch_size,
                                                    shuffle=True,
                                                    class_mode='raw',
                                                    subset='validation',
                                                    interpolation="bilinear"
                                                   )

test_generator = test_datagen.flow_from_dataframe(test,
                                                  x_col='path',
                                                  y_col='health',
                                                  target_size=target_size,
                                                  batch_size=batch_size,
                                                  shuffle=False,
                                                  class_mode='raw',
                                                  interpolation="bilinear"
                                                  )

# Number of epochs
epochs = 2

# Train!
ResnetModel.fit(train_generator,
                  epochs=epochs,
                  validation_data=validation_generator,
                  steps_per_epoch = 3, # Usually cases / batch_size = 3.
                  validation_steps = 1 # Number of validation steps. Again cases / batch_size = 1.
                  )

base_model.trainable = True

ResnetModel.compile(loss=keras.losses.MeanSquaredError(),
                      optimizer=opt
                       )

ResnetModel.summary()

# Define callbacks
checkpoint_path='drive/MyDrive/checkpoints/ImageOnlyModel_128.{epoch:02d}-{val_loss:.2f}.h5'
checkpoint_dir=os.path.dirname(checkpoint_path)

my_callbacks = [
    # Stop training if validation error stays within 0.00001 for three rounds.
    tf.keras.callbacks.EarlyStopping(monitor='val_loss',
                                     min_delta=0.00001,
                                     patience=3),
    # Save the weights of the best performing model to the checkpoint folder.
    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                       save_best_only=True,
                                       save_weights_only=True),
]

# Number of epochs
epochs = 5

# Train!
ResnetModel.fit(train_generator, # Pass the train generator
                  epochs=epochs, # Pass the epochs
                  validation_data=validation_generator, # Pass the validation generator
                  steps_per_epoch = 734,  # Usually cases / batch_size = 3.
                  validation_steps = 184,  # Number of validation steps. Again cases / batch_size = 3.
                  callbacks=my_callbacks # Add the callbacks
                  )

# Plotting training history.
loss = ResnetModel.history.history['loss']
val_loss = ResnetModel.history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Applying to the test set with a generator.
test_generator.reset()

# Get probabilities
output = ResnetModel.predict(test_generator)

output

test['resnet'] = output
test.to_csv('drive/MyDrive/ResNet.csv')

ResnetModel.save('drive/MyDrive/checkpoints/ResnetModel.h5')

!ls drive/MyDrive/*.h5

# Loading
ResnetModel = keras.models.load_model('drive/MyDrive/VGG_lr0.001.h5')

plt.plot(test['health'], output, '.')
plt.show()

ResnetModel.load_weights('drive/MyDrive/ImageOnlyModel_128.02-0.44.h5')
# ResnetModel = keras.models.load_model('drive/MyDrive/checkpoints/ImageOnlyModel.01-0.66.h5')

def mean_absolute_percentage_error(y_true, y_pred): 
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

mape = mean_absolute_percentage_error(test_generator.labels, output)
print('The mean absolute percentual error over the test is %.2f%%' % mape)

import tensorflow as tf

mse = tf.keras.metrics.RootMeanSquaredError()
mse(test['health'], test['resnet']).numpy()

"""**GradCam**"""

# Set the layers.
last_conv_layer_name = "conv5_block3_out"
classifier_layer_names =  ["flatten",
                           "dense",
                           "dropout",
                           "dense_1",
                           "dropout_1",
                           "dense_2",]

# The explainer. Gotten from https://keras.io/examples/vision/grad_cam/
def make_gradcam_heatmap(
    img_array, model, last_conv_layer_name, classifier_layer_names
):
    from tensorflow import keras
    import tensorflow as tf
    # First, we create a model that maps the input image to the activations
    # of the last conv layer. This layer is located at model.layers[1] as the
    # ResNet model is the first "layer" of the ImageOnlyModel. Modify as needed.
    last_conv_layer = model.layers[1].get_layer(last_conv_layer_name)
    last_conv_layer_model = keras.Model(model.layers[1].inputs, last_conv_layer.output)

    # Second, we create a model that maps the activations of the last conv
    # layer to the final class predictions
    regression_input = keras.Input(shape=last_conv_layer.output.shape[1:])
    x = regression_input
    for layer_name in classifier_layer_names:
        try:
            x = model.get_layer(layer_name)(x)
        except:
            x = model.layers[1].get_layer(layer_name)(x)
    regression_model = keras.Model(regression_input, x)

    # Then, we compute the gradient of the top predicted class for our input image
    # with respect to the activations of the last conv layer
    with tf.GradientTape() as tape:
        # Compute activations of the last conv layer and make the tape watch it
        last_conv_layer_output = last_conv_layer_model(img_array)
        tape.watch(last_conv_layer_output)
        # Compute predictions
        top_class_channel = regression_model(last_conv_layer_output)

    # This is the gradient of the top predicted class with regard to
    # the output feature map of the last conv layer
    grads = tape.gradient(top_class_channel, last_conv_layer_output)

    # This is a vector where each entry is the mean intensity of the gradient
    # over a specific feature map channel
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    # We multiply each channel in the feature map array
    # by "how important this channel is" with regard to the regression
    last_conv_layer_output = last_conv_layer_output.numpy()[0]
    pooled_grads = pooled_grads.numpy()
    for i in range(pooled_grads.shape[-1]):
        last_conv_layer_output[:, :, i] *= pooled_grads[i]

    # The channel-wise mean of the resulting feature map
    # is our heatmap of activation
    heatmap = np.mean(last_conv_layer_output, axis=-1)

    # For visualization purpose, we will also normalize the heatmap between 0 & 1
    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)

    return heatmap

# Commented out IPython magic to ensure Python compatibility.
# Display
from IPython.display import Image
import matplotlib.pyplot as plt
import matplotlib.cm as cm
# %matplotlib inline
# from tensorflow.keras.applications.vgg19 import preprocess_input
from tensorflow.keras.applications.resnet_v2 import preprocess_input

# Get the image in the right size
def get_img_array(img_path, size = (224, 224)):
    import tensorflow as tf
    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)
    # `array` is a float32 Numpy array of shape (299, 299, 3)
    array = tf.keras.preprocessing.image.img_to_array(img)
    # We add a dimension to transform our array into a "batch"
    # of size (1, 224, 224, 3)
    array = np.expand_dims(array, axis=0)
    array = preprocess_input(array)
    return array

# Get an image
img_path = 'drive/MyDrive/new/LIDAR/LIDAR_61893.png'
data = get_img_array(img_path)

# Plot it
display(Image(img_path))

# Plot the heatmap!
heatmap = make_gradcam_heatmap(
    data, ResnetModel, last_conv_layer_name, classifier_layer_names
)

# Display heatmap
plt.matshow(heatmap)
plt.show()

# VGG_out.loc[((VGG_out['VGG'] - VGG_out['health']).abs() <0.5) & ((VGG_out['health'] )<4) & ((VGG_out['health'] )>3), ['health', 'VGG', 'path']]

# We load the original image
img = keras.preprocessing.image.load_img(img_path)
img = keras.preprocessing.image.img_to_array(img)

# We rescale heatmap to a range 0-255
heatmap = np.uint8(255 * heatmap)

# We use jet colormap to colorize heatmap
jet = cm.get_cmap("jet")

# We use RGB values of the colormap
jet_colors = jet(np.arange(256))[:, :3]
jet_heatmap = jet_colors[heatmap]

# We create an image with RGB colorized heatmap
jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)
jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))
jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)

# Superimpose the heatmap on original image
superimposed_img = jet_heatmap * 0.4 + img
superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)

# Save the superimposed image
save_path = "Example.jpg"
superimposed_img.save(save_path)

# Display Grad RAM
display(Image(save_path))

"""**Multi-Modal Learning**"""

# Import preprocessors
from sklearn.preprocessing import MinMaxScaler

# What are the continous variables?
continousCols = ['income', 'employment', 'education', 'crime', 'barriers', 'living_environment']

# Define scaler and train it over the train set.
Scaler = MinMaxScaler()
Scaler.fit(train[continousCols])

# Apply over sets. Ignore warning.
train[continousCols] = Scaler.transform(train[continousCols])
test[continousCols] = Scaler.transform(test[continousCols])

from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input

image_input = tf.keras.Input(shape=ImageSize + (3,),
                             name = 'image_input')

# Load an empty ResNet
resnet_input = ResNet50V2(weights = 'imagenet',     # The weights from the ImageNet competition
                      include_top = False,       # Do not include the top layer, which classifies.
                      input_shape= (224, 224, 3) # Input shape. Three channels.
                      )
resnet_input.trainable = False

# Use the model API to attach it to our input layer.
ImageClassifier = resnet_input(image_input, training=False)

# Add a Flatten layer with the model API.
ImageClassifier = Flatten()(ImageClassifier)

# Now we create the structured data layer.
predictive_features = 6
features_input  = keras.Input(shape=(predictive_features,),
                              name="structured_data") 
Structured =  Dense( 12, activation = 'relu' )(features_input) # Add one processing layer
Structured =  Dropout(0.5)(Structured)   # Dropout after  Dense
Structured =  Dense( 6, activation = 'relu' )(Structured)
Structured =  Dropout(0.5)(Structured)   # Dropout after  Dense

# Merge all available features into a single large vector via concatenation
merged = concatenate([ImageClassifier, Structured])

# Add a few prediction layers
merged = Dense(256, activation='relu')(merged)
merged = Dropout(0.5)(merged)

house_price_multi = Dense(1, activation='relu', name="health_index")(merged)

# Instantiate an end-to-end model predicting house_prices
multimodal_model = keras.Model(inputs=[image_input, features_input], 
                               outputs=[house_price_multi])

opt = optimizers.Adam(learning_rate=1e-5,            # Learning rate needs to be tweaked for convergence and be small!
                      decay=1e-3 / 200    # Decay of the LR 10^-3 / 1 / 50 / 100 / 200
                      )

# Compile with same optimizer as before.
multimodal_model.compile(optimizer = opt,
                    loss='MeanSquaredError')

import pydot as pyd
from tensorflow.keras.utils import plot_model

#Visualize Model
plot_model(
          multimodal_model, to_file='model.png', show_shapes=False, show_layer_names=True,
          rankdir='TB', expand_nested=False, dpi=96
          )

# Define parameters

target_size = (224, 224)
batch_size = 32
DataDir = 'HousesDatasetClean'

# What are the useful columns? Note the position of the target. 
pred_cols = np.r_[np.r_[11:(train.columns.shape[0]-1)]]

# We only modify the generators. Note the y vector.

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define generators
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.resnet_v2 import preprocess_input
train_datagen = ImageDataGenerator(
                                  rescale=None,                         # Inputs are scaled in the preprocessing function
                                  shear_range=0,                          # Shear?
                                  zoom_range=0.2,                           # Zoom? 0.2 means from 80% to 120%
                                  horizontal_flip=False,                     # Flip horizontally?
                                  vertical_flip=False,                      # Flip vertically?
                                  preprocessing_function=preprocess_input,  # ResNet expects specific input. Set it up with this function that comes prepackaged.
                                  validation_split = 0.2                    # Create a validation cut?
                                  )

test_datagen = ImageDataGenerator(
                                  rescale=None,                        # Inputs are scaled in the preprocessing function
                                  shear_range=0,                          # Shear?
                                  zoom_range=0,                           # Zoom? 0.2 means from 80% to 120%
                                  horizontal_flip=False,                     # Flip horizontally?
                                  vertical_flip=False,                      # Flip vertically?
                                  preprocessing_function=preprocess_input,  # VGG expects specific input. Set it up with this function that comes prepackaged.
                                  )



train_generator = train_datagen.flow_from_dataframe(train,
                                                    directory='.',
                                                    x_col='path',
                                                    y_col=train.columns[pred_cols],
                                                    target_size=target_size,
                                                    batch_size=batch_size,
                                                    shuffle=True,
                                                    class_mode='raw',
                                                    subset='training',
                                                    interpolation="bilinear"
                                                   )

validation_generator = train_datagen.flow_from_dataframe(train,
                                                    directory='.',
                                                    x_col='path',
                                                    y_col=train.columns[pred_cols],
                                                    target_size=target_size,
                                                    batch_size=batch_size,
                                                    shuffle=True,
                                                    class_mode='raw',
                                                    subset='validation',
                                                    interpolation="bilinear"
                                                   )

test_generator = test_datagen.flow_from_dataframe(test,
                                                  x_col='path',
                                                  y_col=test.columns[pred_cols],
                                                  target_size=target_size,
                                                  batch_size=batch_size,
                                                  shuffle=False,
                                                  class_mode='raw',
                                                  interpolation="bilinear"
                                                  )
# Define combined generator
def train_generator_func():
    count = 0

    while True:
        if  count == len(train.index):
            train_generator.reset()
            break
        count += 1
        data = train_generator.next()

        # Let's identify where is what.
        target_location = 3
        predictive_columns = np.r_[0:3, 4:7]

        # Now we reshape everything. First the images.
        imgs = data[0]
        # Now we need to extract which ones are the predictive variables.
        cols = data[1][:, predictive_columns]
        # Finally we need the targets.
        targets = data[1][:, target_location]
        yield [imgs, cols], targets


def validation_generator_func():
    count = 0
    while True:
        if count == len(train.index):
            validation_generator.reset()
            break
        count += 1
        data = validation_generator.next()

        # Let's identify where is what.
        target_location = 3
        predictive_columns = np.r_[0:3, 4:7]

        # Now we reshape everything. First the images.
        imgs = data[0]
        # Now we need to extract which ones are the predictive variables.
        cols = data[1][:, predictive_columns]
        # Finally we need the targets.
        targets = data[1][:, target_location]
        yield [imgs, cols], targets
        
        
def test_generator_func():
    count = 0
    test_generator.reset()
    while True:
        if count == len(test.index):
            test_generator.reset()
            break
        count += 1
        data = test_generator.next()

        # Let's identify where is what.
        target_location = 3
        predictive_columns = np.r_[0:3, 4:7]

        # Now we reshape everything. First the images.
        imgs = data[0]
        # Now we need to extract which ones are the predictive variables.
        cols = data[1][:, predictive_columns]
        # Finally we need the targets.
        targets = data[1][:, target_location]
        yield [imgs, cols], targets

train.columns[pred_cols]

# This is how the data comes out now.
train_test_output = validation_generator_func()
next(train_test_output)

np.amax([validation_generator.samples // validation_generator.batch_size, 1])

# Warmup
# Steps and epochs
epochs=3
steps_per_epoch = train_generator.samples // train_generator.batch_size
validation_steps = np.amax([validation_generator.samples // validation_generator.batch_size, 1])

# Train!
multimodal_model.fit(train_generator_func(),
                      epochs=epochs,
                      steps_per_epoch=steps_per_epoch,
                      validation_data=validation_generator_func(),
                      validation_steps=validation_steps
                     )

multimodal_model.load_weights('drive/MyDrive/checkpoints/MultimodalModel04-0.37.h5')

# Set it as trainable
resnet_input.trainable = True

# Recompile
multimodal_model.compile(optimizer = opt,
                    loss='MeanSquaredError')

# Define callbacks
checkpoint_path='drive/MyDrive/checkpoints/MultimodalModel{epoch:02d}-{val_loss:.2f}.h5'
checkpoint_dir=os.path.dirname(checkpoint_path)

my_callbacks = [
    # Stop training if validation error stays within 0.00001 for three rounds.
    tf.keras.callbacks.EarlyStopping(monitor='val_loss', 
                                     min_delta=0.00001,
                                     patience=3),
    # Save the weights of the best performing model to the checkpoint folder.
    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                       save_best_only=True,
                                       save_weights_only=True,
                                       monitor='val_loss'
                                       ),
]

# Steps and epochs
epochs=5
steps_per_epoch = train_generator.samples // train_generator.batch_size
validation_steps = np.amax([validation_generator.samples // validation_generator.batch_size, 1])

# Train!
multimodal_model.fit(train_generator_func(),
                      epochs=epochs,
                      steps_per_epoch=steps_per_epoch,
                      validation_data=validation_generator_func(),
                      validation_steps=validation_steps,
                     callbacks=my_callbacks
                     )

loss = multimodal_model.history.history['loss']
val_loss = multimodal_model.history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Calculate outputs in test set
STEP_SIZE_TEST = test_generator.n//test_generator.batch_size

house_test = multimodal_model.predict(test_generator_func(),
                                    steps=STEP_SIZE_TEST+1,
                                    verbose=1)

def mean_absolute_percentage_error(y_true, y_pred): 
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

mape = mean_absolute_percentage_error(test_generator.labels[:,3], house_test)
print('The mean absolute percentual error over the test is %.2f%%' % mape)